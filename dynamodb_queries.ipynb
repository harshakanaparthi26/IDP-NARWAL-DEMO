{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DynamoDB Query Notebook\n",
    "Query processed documents, extraction results, and pipeline errors.\n",
    "\n",
    "**Table structure:**\n",
    "- `DOC#{doc_id}` / `META` → document metadata + status\n",
    "- `DOC#{doc_id}` / `EXTRACTION_COMPARISON` → entity extraction results\n",
    "- `DOC#{doc_id}` / `ERROR#{step}#{timestamp}` → pipeline errors\n",
    "- **GSI1**: query all docs processed on a given date\n",
    "- **GSI2**: query all failed documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "from boto3.dynamodb.conditions import Key\n",
    "\n",
    "# ── Config ────────────────────────────────────────────────────────────────────\n",
    "AWS_REGION     = 'us-east-2'\n",
    "DYNAMODB_TABLE = 'wp-phoenix-statement-reporting-table'\n",
    "\n",
    "dynamodb = boto3.resource('dynamodb', region_name=AWS_REGION)\n",
    "table    = dynamodb.Table(DYNAMODB_TABLE)\n",
    "\n",
    "# Helper: convert Decimal back to float for display\n",
    "def _clean(obj):\n",
    "    if isinstance(obj, Decimal):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: _clean(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, list):\n",
    "        return [_clean(i) for i in obj]\n",
    "    return obj\n",
    "\n",
    "print('Connected to:', DYNAMODB_TABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Get all doc IDs processed today (or any date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this date to query a different day\n",
    "query_date = '2026-02-15'   # format: YYYY-MM-DD\n",
    "\n",
    "resp = table.query(\n",
    "    IndexName='GSI1',\n",
    "    KeyConditionExpression=Key('GSI1PK').eq(f'DATE#{query_date}')\n",
    ")\n",
    "\n",
    "docs_today = [_clean(item) for item in resp.get('Items', [])]\n",
    "\n",
    "if docs_today:\n",
    "    df = pd.DataFrame([{\n",
    "        'doc_id':          d.get('doc_id'),\n",
    "        'doc_name':        d.get('doc_name'),\n",
    "        'status':          d.get('status'),\n",
    "        'created_at':      d.get('created_at'),\n",
    "        'merchant_group':  d.get('merchant_group'),\n",
    "        'volume_tier_tsg': d.get('volume_tier_tsg'),\n",
    "    } for d in docs_today])\n",
    "    print(f'Found {len(df)} document(s) processed on {query_date}')\n",
    "    display(df)\n",
    "else:\n",
    "    print(f'No documents found for {query_date}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Get full metadata for a specific doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste any doc_id from the list above\n",
    "DOC_ID = 'PASTE_DOC_ID_HERE'\n",
    "\n",
    "resp = table.get_item(\n",
    "    Key={'PK': f'DOC#{DOC_ID}', 'SK': 'META'}\n",
    ")\n",
    "\n",
    "meta = _clean(resp.get('Item', {}))\n",
    "\n",
    "if meta:\n",
    "    print(f\"Document : {meta.get('doc_name')}\")\n",
    "    print(f\"Status   : {meta.get('status')}\")\n",
    "    print(f\"Created  : {meta.get('created_at')}\")\n",
    "    print(f\"Completed: {meta.get('completed_at')}\")\n",
    "    print(f\"S3 text  : {meta.get('s3_text_key')}\")\n",
    "    print(f\"OS index : {meta.get('opensearch_index_name')}\")\n",
    "    print(f\"Chars    : {meta.get('char_count'):,}\" if meta.get('char_count') else \"Chars: —\")\n",
    "    print(f\"Tables   : {meta.get('table_count')}\")\n",
    "    print(f\"Industry : {meta.get('merchant_group')}\")\n",
    "    print(f\"Tier     : {meta.get('volume_tier_tsg')}\")\n",
    "else:\n",
    "    print(f'No metadata found for doc_id: {DOC_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Get extraction results for a doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses DOC_ID from cell above — or paste a different one\n",
    "# DOC_ID = 'PASTE_DOC_ID_HERE'\n",
    "\n",
    "resp = table.get_item(\n",
    "    Key={'PK': f'DOC#{DOC_ID}', 'SK': 'EXTRACTION_COMPARISON'}\n",
    ")\n",
    "\n",
    "ext = _clean(resp.get('Item', {}))\n",
    "\n",
    "if ext:\n",
    "    print('── Single Prompt Results ──────────────────────────────')\n",
    "    sp = ext.get('single_prompt', {})\n",
    "    print(f\"  total_amount             : {sp.get('total_amount')}\")\n",
    "    print(f\"  total_transactions_count : {sp.get('total_transactions_count')}\")\n",
    "    print(f\"  total_fees               : {sp.get('total_fees')}\")\n",
    "\n",
    "    print('\\n── Separate Prompts Results ───────────────────────────')\n",
    "    sep = ext.get('separate_prompts', {})\n",
    "    print(f\"  total_amount             : {sep.get('total_amount')}\")\n",
    "    print(f\"  total_transactions_count : {sep.get('total_transactions_count')}\")\n",
    "    print(f\"  total_fees               : {sep.get('total_fees')}\")\n",
    "\n",
    "    print('\\n── Match Flags ────────────────────────────────────────')\n",
    "    for k, v in (ext.get('match_flags') or {}).items():\n",
    "        print(f\"  {k}: {'✓ match' if v else '✗ mismatch'}\")\n",
    "\n",
    "    print('\\n── Judge Verdicts (separate prompts) ──────────────────')\n",
    "    for k, v in (ext.get('judge_verdicts') or {}).items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    print('\\n── Effective Rate + Benchmark ─────────────────────────')\n",
    "    print(f\"  effective_rate_raw     : {ext.get('effective_rate_raw')}\")\n",
    "    print(f\"  benchmark_raw          : {ext.get('benchmark_raw')}\")\n",
    "    print(f\"  delta_vs_benchmark_raw : {ext.get('delta_vs_benchmark_raw')}\")\n",
    "    print(f\"  merchant_group         : {ext.get('merchant_group')}\")\n",
    "    print(f\"  volume_tier_tsg        : {ext.get('volume_tier_tsg')}\")\n",
    "else:\n",
    "    print(f'No extraction results found for doc_id: {DOC_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Get all pipeline errors for a doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses DOC_ID from above — or paste a different one\n",
    "# DOC_ID = 'PASTE_DOC_ID_HERE'\n",
    "\n",
    "resp = table.query(\n",
    "    KeyConditionExpression=\n",
    "        Key('PK').eq(f'DOC#{DOC_ID}') &\n",
    "        Key('SK').begins_with('ERROR#')\n",
    ")\n",
    "\n",
    "errors = [_clean(item) for item in resp.get('Items', [])]\n",
    "\n",
    "if errors:\n",
    "    print(f'Found {len(errors)} error(s) for doc_id: {DOC_ID}\\n')\n",
    "    for e in errors:\n",
    "        print(f\"Step       : {e.get('step')}\")\n",
    "        print(f\"Time       : {e.get('created_at')}\")\n",
    "        print(f\"Error      : {e.get('error_message')}\")\n",
    "        print(f\"Traceback  :\\n{e.get('traceback')}\")\n",
    "        print('─' * 60)\n",
    "else:\n",
    "    print(f'No errors recorded for doc_id: {DOC_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Get ALL failed documents across the system (any doc, any date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = table.query(\n",
    "    IndexName='GSI2',\n",
    "    KeyConditionExpression=Key('GSI2PK').eq('STATUS#ERROR')\n",
    ")\n",
    "\n",
    "all_errors = [_clean(item) for item in resp.get('Items', [])]\n",
    "\n",
    "if all_errors:\n",
    "    df_errors = pd.DataFrame([{\n",
    "        'doc_id':        e.get('doc_id'),\n",
    "        'step':          e.get('step'),\n",
    "        'error_message': e.get('error_message'),\n",
    "        'created_at':    e.get('created_at'),\n",
    "    } for e in all_errors]).sort_values('created_at', ascending=False)\n",
    "    print(f'Total errors across all documents: {len(df_errors)}')\n",
    "    display(df_errors)\n",
    "else:\n",
    "    print('No pipeline errors found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Compare extraction methods across all documents (single vs separate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get doc_ids from today (reuse from cell 1) or build your own list\n",
    "# doc_ids = ['abc123', 'def456', ...]   # manual list\n",
    "doc_ids = [d.get('doc_id') for d in docs_today if d.get('doc_id')]\n",
    "\n",
    "rows = []\n",
    "for doc_id in doc_ids:\n",
    "    resp = table.get_item(\n",
    "        Key={'PK': f'DOC#{doc_id}', 'SK': 'EXTRACTION_COMPARISON'}\n",
    "    )\n",
    "    ext = _clean(resp.get('Item', {}))\n",
    "    if not ext:\n",
    "        continue\n",
    "\n",
    "    sp  = ext.get('single_prompt',   {})\n",
    "    sep = ext.get('separate_prompts', {})\n",
    "    mf  = ext.get('match_flags',      {})\n",
    "\n",
    "    rows.append({\n",
    "        'doc_id':                     doc_id,\n",
    "        'single_amount':              sp.get('total_amount'),\n",
    "        'separate_amount':            sep.get('total_amount'),\n",
    "        'single_fees':                sp.get('total_fees'),\n",
    "        'separate_fees':              sep.get('total_fees'),\n",
    "        'single_txn_count':           sp.get('total_transactions_count'),\n",
    "        'separate_txn_count':         sep.get('total_transactions_count'),\n",
    "        'match_amount':               mf.get('match_total_amount'),\n",
    "        'match_fees':                 mf.get('match_total_fees'),\n",
    "        'match_txn':                  mf.get('match_total_transactions_count'),\n",
    "        'effective_rate_raw':         ext.get('effective_rate_raw'),\n",
    "        'benchmark_raw':              ext.get('benchmark_raw'),\n",
    "        'delta_vs_benchmark_raw':     ext.get('delta_vs_benchmark_raw'),\n",
    "    })\n",
    "\n",
    "if rows:\n",
    "    df_compare = pd.DataFrame(rows)\n",
    "    print(f'Extraction comparison across {len(df_compare)} document(s):')\n",
    "    display(df_compare)\n",
    "\n",
    "    # Agreement rate\n",
    "    for col in ['match_amount', 'match_fees', 'match_txn']:\n",
    "        rate = df_compare[col].mean() * 100 if col in df_compare else 0\n",
    "        print(f'{col}: {rate:.0f}% agreement between methods')\n",
    "else:\n",
    "    print('No extraction comparison data found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Get all records for a doc_id (full audit trail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns every record stored for this document\n",
    "# DOC_ID = 'PASTE_DOC_ID_HERE'\n",
    "\n",
    "resp = table.query(\n",
    "    KeyConditionExpression=Key('PK').eq(f'DOC#{DOC_ID}')\n",
    ")\n",
    "\n",
    "all_records = [_clean(item) for item in resp.get('Items', [])]\n",
    "\n",
    "print(f'All records for DOC#{DOC_ID}:')\n",
    "for r in all_records:\n",
    "    print(f\"  SK = {r.get('SK')}\")\n",
    "\n",
    "print(f'\\nTotal: {len(all_records)} record(s)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
